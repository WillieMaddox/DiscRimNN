{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DiscRimNN\n",
    "## Option 1\n",
    "Create a model that reads a sequence of numbers, one number at a time, and classify that number based on all previously seen numbers.\n",
    "\n",
    "## Option 2\n",
    "Create a model that reads a sequence of numbers and classifies the last number in the sequence based on the previous numbers in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How this project is useful\n",
    " 1. full control over dataset\n",
    " 2. infinite dataset\n",
    " 3. can study all three RNN base problems (classification, prediction, forcasting).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Project Steps\n",
    " 1. create dataset\n",
    " 2. create network\n",
    " 3. train network\n",
    " 4. test network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## TODO\n",
    " - [x] create single signal generator class\n",
    " - [x] create mixed signal generator class\n",
    " - [ ] create signal noise functions (Gaussian, OU, etc.)\n",
    " - [ ] create timestep noise functions \n",
    " - [x] add legends to plots.\n",
    " - [ ] during training, save outlier X, y train sets to file for further analysis.\n",
    " - [x] save configuration of mixed signal properties as json.\n",
    " - [ ] make plots of the mixed signal with colors mapped to hidden layers, lstm states, etc.\n",
    " - [ ] unit tests for signal.py\n",
    " - [ ] create startup.py to handle project directories and other goodies.\n",
    " - [ ] fix savefig clipping the bottoms of our figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data generator parameters to test\n",
    " 1. All 4 wave variables\n",
    "  - amplitude\n",
    "  - frequency (period)\n",
    "  - offset\n",
    "  - phase\n",
    " 2. sequence length\n",
    " 3. signal noise\n",
    " 4. timestep noise\n",
    " 5. number of signals\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Model hyperparameters to test\n",
    " - number of timestamps `n_timestamps`\n",
    " - number of timesteps `n_timesteps`\n",
    " - number of neurons per LSTM `n_neurons`\n",
    " - number of LSTM recurrent cells\n",
    " - number of LSTM layers\n",
    " - number of epochs\n",
    " - batch_size\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Questions to answer\n",
    " 1. What would a batch look like?\n",
    " 2. How many LSTM layers do we need? nodes per LSTM layer?\n",
    " 3. Can we learn if our timestamps are not uniformly spaced.\n",
    " 4. Should we make the LSTM layers stateful?\n",
    " 5. Should we use sliding window or boxcar sequences?\n",
    " 6. For stateful LSTM's must we `model.reset_states()` after any `model.evaluate()` and/or `model.predict()` calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "# import h5py\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "from random import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_column_matches(data, column='', color='yellow'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_mixed = data == data[column]\n",
    "        return [attr if v else '' for v in is_mixed]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_mixed = data == data[column]\n",
    "        return pd.DataFrame(np.where(is_mixed, attr, ''), index=data.index, columns=data.columns)\n",
    "\n",
    "def get_timestamp(t=None, format='%Y-%m-%d_%H-%M-%S'):\n",
    "    \"\"\"Return timestamp as a string; default: current time, format: YYYY-DD-MM_hh-mm-ss.\"\"\"\n",
    "    if t is None:\n",
    "        t = datetime.now()\n",
    "    return t.strftime(format)\n",
    "\n",
    "def plot_stats(csv_filename, columns=['total_reward'], **kwargs):\n",
    "    \"\"\"Plot specified columns from CSV file.\"\"\"\n",
    "    df_stats = pd.read_csv(csv_filename)\n",
    "    df_stats[columns].plot(**kwargs)\n",
    "\n",
    "# Ref http://connor-johnson.com/2014/02/01/smoothing-with-exponentially-weighted-moving-averages/\n",
    "def holt_winters_second_order_ewma(x, span, beta):\n",
    "    N = x.size\n",
    "    alpha = 2.0 / (1 + span)\n",
    "    s = np.zeros((N,))\n",
    "    b = np.zeros((N,))\n",
    "    s[0] = x[0]\n",
    "    for i in range(1, N):\n",
    "        s[i] = alpha * x[i] + (1 - alpha) * (s[i-1] + b[i-1])\n",
    "        b[i] = beta * (s[i] - s[i-1]) + (1 - beta) * b[i-1]\n",
    "    return s\n",
    "\n",
    "def reversed_recombined_holt_winters(x, span=15, beta=0.3):\n",
    "    # take EWMA in both directions with a smaller span term\n",
    "    fwd = holt_winters_second_order_ewma(x, span, beta)\n",
    "    bwd = holt_winters_second_order_ewma(x[::-1], span, beta)\n",
    "    c = np.vstack((fwd, bwd[::-1])) # lump fwd and bwd together\n",
    "    c = np.mean(c, axis=0) # average\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a signal generator\n",
    "\n",
    "The signal generator builds waves using the standard form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$x(t) = h + A\\sin\\left(\\frac{2\\pi t}{T} + \\phi\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "where $h$ is the height (vertical offset), $A$ is the amplitude (vertical scale), $T$ is the period (horizontal scale), and $\\phi$ is the phase (horizontal offset). This give us fine grained control over how we construct our waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from discrimnn.signal import MixedSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# start off with simplest case for proof of concept\n",
    "sig1_coeffs = {\n",
    "    'amplitude': {'mean': 1.0, 'delta': 0}, \n",
    "    'offset': {'mean': -3, 'delta': 0}, \n",
    "    'period': {'mean': 1, 'delta': 0},\n",
    "    'phase': {'mean': 0, 'delta': 0},\n",
    "    'name': 'A',\n",
    "    'color': '#ff0000'\n",
    "}\n",
    "sig2_coeffs = {\n",
    "    'amplitude': {'mean': 1.0, 'delta': 0}, \n",
    "    'offset': {'mean': 0.0, 'delta': 0}, \n",
    "    'period': {'mean': 1, 'delta': 0},\n",
    "    'phase': {'mean': 0, 'delta': 0},\n",
    "    'name': 'B',\n",
    "    'color': '#00ff00'\n",
    "}\n",
    "sig3_coeffs = {\n",
    "    'amplitude': {'mean': 1.0, 'delta': 0}, \n",
    "    'offset': {'mean': 3, 'delta': 0}, \n",
    "    'period': {'mean': 1, 'delta': 0},\n",
    "    'phase': {'mean': 0, 'delta': 0},\n",
    "    'name': 'C',\n",
    "    'color': '#0000ff'\n",
    "}\n",
    "sig_coeffs = [sig1_coeffs, sig2_coeffs, sig3_coeffs]\n",
    "\n",
    "msig_coeffs = {\n",
    "    'phase': {'mean': 0, 'delta': np.pi}, \n",
    "#     'amplitude': {'mean': 10, 'delta': 2}, \n",
    "    'period': {'mean': 25, 'delta': 0}, \n",
    "#     'offset': {'mean': 1, 'delta': 5}\n",
    "}\n",
    "# msig_coeffs = {}\n",
    "\n",
    "t_initial = 0\n",
    "t_final = 75\n",
    "n_timestamps = 301\n",
    "n_timesteps = 10\n",
    "time_coeffs = {'start': t_initial, 'stop': t_final, 'n_timestamps': n_timestamps, 'n_timesteps': n_timesteps}\n",
    "\n",
    "msig = MixedSignal(time_coeffs, sig_coeffs, msig_coeffs, run_label='offset_30', method='sliding')\n",
    "msig.save_config()\n",
    "X, y = msig.generate()\n",
    "n_signals = msig.n_signals\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.vstack((msig.signals, msig.mixed_signal)).T, index=msig.timestamps, columns=['A', 'B', 'C', 'Mixed'])\n",
    "df = pd.DataFrame(np.vstack((msig.timestamps, msig.signals, msig.mixed_signal)).T, columns=['time', 'A', 'B', 'C', 'Mixed'])\n",
    "df[:n_timesteps + 4].style.apply(highlight_column_matches, column='Mixed', color='lightblue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "legend_labels = []\n",
    "for i in range(msig.n_signals):\n",
    "    ax.plot(msig.timestamps, msig.signals[i], marker='.', color=msig.signal_objects[i].color)\n",
    "    legend_labels.append(msig.signal_objects[i].name)\n",
    "ax.set_xlim((t_initial, t_final))\n",
    "plt.grid(True)\n",
    "ax.legend(legend_labels)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'signals.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', marker='.', alpha=0.3)\n",
    "# ax.scatter(msig.timestamps, msig.mixed_signal, color='grey', marker='.')\n",
    "ax.set_xlim((t_initial, t_final))\n",
    "plt.grid(True)\n",
    "ax.legend([msig.name], loc='upper right', bbox_to_anchor=(0.99, 0.99))\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixedsignal.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=msig.one_hots)\n",
    "ax.set_xlim((t_initial, t_final))\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixedsignal_with_truth.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_neurons = 32\n",
    "n_layers = 1\n",
    "batch_size = 4\n",
    "# define model\n",
    "model = Sequential()\n",
    "# model.add(Masking(mask_value=-1, input_shape=(1,)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(n_timesteps, 1), return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, input_shape=self.input_shape, return_sequences=False, dropout=0.5))\n",
    "# model.add(LSTM(n_neurons, input_shape=(2, 1)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(n_timesteps, 2)))\n",
    "model.add(LSTM(n_neurons, batch_input_shape=(batch_size, n_timesteps, 1), stateful=True, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(n_timesteps, 1, 1), stateful=True, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(n_timesteps, 1, 1), stateful=True))\n",
    "# model.add(LSTM(n_neurons, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons))\n",
    "# for _ in range(n_layers):\n",
    "#     model.add(LSTM(n_neurons, stateful=True, return_sequences=True))\n",
    "model.add(LSTM(n_neurons, stateful=True))\n",
    "model.add(Dense(n_signals, activation='softmax'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Reshape((n_neurons, n_signals, 1)))\n",
    "# model.add(TimeDistributed(Dense(msig.n_signals, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_config_filename = os.path.join(msig.out_dir, 'model_config.json')\n",
    "model_summary_filename = os.path.join(msig.out_dir, 'model_plot.png')\n",
    "with open(model_config_filename, 'w') as ofs:\n",
    "    json.dump(json.loads(model.to_json()), ofs, indent=4)\n",
    "\n",
    "plot_model(model, to_file=model_summary_filename, show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_generations = 20\n",
    "n_epochs = 1\n",
    "save_every = 10\n",
    "\n",
    "model_weights_filename = os.path.join(msig.out_dir, 'model_weights.h5')\n",
    "training_stats_filename = os.path.join(msig.out_dir, 'training_stats.csv')\n",
    "stats = {'gen': [], 'loss': [], 'acc': []}\n",
    "for i in range(n_generations):\n",
    "#     X, y = msig.generate_batch(64)\n",
    "    X, y = msig.generate()\n",
    "    history = model.fit(X, y, \n",
    "                        epochs=n_epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        verbose=1, \n",
    "                        shuffle=False)\n",
    "    stats['gen'].append(i+1)\n",
    "    stats['loss'].append(history.history['loss'][-1])\n",
    "    stats['acc'].append(history.history['acc'][-1])\n",
    "    model.reset_states()\n",
    "    if i % save_every == 0:\n",
    "        model.save_weights(model_weights_filename)\n",
    "        df_stats = pd.DataFrame.from_dict(stats)\n",
    "        df_stats.to_csv(training_stats_filename, mode='w', index=False, header=True)\n",
    "\n",
    "model.save_weights(model_weights_filename)\n",
    "df_stats = pd.DataFrame.from_dict(stats)\n",
    "df_stats.to_csv(training_stats_filename, mode='w', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "\n",
    "ax[0].plot(df_stats.loss)\n",
    "# ax[0].plot(df_stats.loss, color='grey', alpha=0.3)\n",
    "# hw_loss = reversed_recombined_holt_winters(np.array(df_stats.loss))\n",
    "# ax[0].plot(hw_loss)\n",
    "ax[0].set_title(r'n_timestamps = {}, n_timesteps = {}'.format(n_timestamps, n_timesteps))\n",
    "ax[0].set_xlabel(r'generation')\n",
    "ax[0].set_xlim((0, n_generations))\n",
    "ax[0].set_ylabel(r'loss')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(df_stats.acc)\n",
    "# ax[1].plot(df_stats.acc, color='grey', alpha=0.3)\n",
    "# hw_acc = reversed_recombined_holt_winters(np.array(df_stats.acc))\n",
    "# ax[1].plot(hw_acc)\n",
    "ax[1].set_title(r'n_neurons = {}, batch_size = {}'.format(n_neurons, batch_size))\n",
    "ax[1].set_xlabel(r'generation')\n",
    "ax[1].set_xlim((0, n_generations))\n",
    "ax[1].set_ylabel(r'accuracy')\n",
    "ax[1].grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'loss_acc.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "# y_pred_colors = [msig.signal_objects[i].color for i in msig.classes[msig.n_timesteps-1:]]\n",
    "y_pred_colors = [msig.signal_objects[i].color for i in y_pred]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax.scatter(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], marker='.', c=y_pred_colors)\n",
    "ax.set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax.set_xlabel('time')\n",
    "ax.set_xlim(t_initial, t_final)\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'eval_pred.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "print(score)\n",
    "\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "y_error = 1.0 - np.max(y_hat, axis=1)\n",
    "print(y_hat.shape)\n",
    "print(y_pred.shape)\n",
    "print(y_error.shape)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 6))\n",
    "\n",
    "ax[0].plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax[0].scatter(msig.timestamps, msig.mixed_signal, marker='.')\n",
    "ax[0].set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax[0].set_xlim(t_initial, t_final)\n",
    "\n",
    "ax[1].plot(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "ax[1].scatter(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "ax[1].set_xlim(t_initial, t_final)\n",
    "ax[1].set_xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_batch = 1\n",
    "print(X.shape)\n",
    "print(n_batch)\n",
    "# re-define model\n",
    "new_model = Sequential()\n",
    "new_model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
    "new_model.add(LSTM(n_neurons))\n",
    "new_model.add(Dense(msig.n_signals, activation='softmax'))\n",
    "# copy weights\n",
    "old_weights = model.get_weights()\n",
    "new_model.set_weights(old_weights)\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "x_test, y_test = msig.generate()\n",
    "score = new_model.evaluate(x_test, y_test, batch_size=n_batch)\n",
    "print(score)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=msig.one_hots)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "for i in range(len(x_test)):\n",
    "    print('Expected', y_test[i], 'Predicted', y_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "print(y_hat.shape)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "print(y_pred.shape)\n",
    "y_error = np.max(y_hat, axis=1)\n",
    "print(y_error.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.n_timesteps-1:], x_test[:, -1, 0], marker='.', c=y_error)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[-msig.n_samples:], y_error, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[-msig.n_samples:], y_error, marker='.', c=y_error)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
