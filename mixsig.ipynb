{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MixSig\n",
    "## Option 1\n",
    "Create a model that reads a sequence of numbers, one number at a time, and classify that number based on all previously seen numbers.\n",
    "\n",
    "## Option 2\n",
    "Create a model that reads a sequence of numbers and classifies the last number in the sequence based on the previous numbers in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How this project is useful\n",
    " 1. full control over dataset\n",
    " 2. infinite dataset\n",
    " 3. can study all three RNN base problems (classification, prediction, forcasting).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Project Steps\n",
    " 1. create dataset\n",
    " 2. create network\n",
    " 3. train network\n",
    " 4. test network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## TODO\n",
    " - [x] create single signal generator class\n",
    " - [x] create mixed signal generator class\n",
    " - [ ] create signal noise functions (Gaussian, etc.)\n",
    " - [ ] create timestep noise functions \n",
    " - [x] add legends to plots.\n",
    " - [ ] during training, save outlier X, y train sets to file for further analysis.\n",
    " - [x] save configuration of mixed signal properties as json.\n",
    " - [ ] make plots of the mixed signal with colors mapped to hidden layers, lstm states, etc.\n",
    " - [ ] unit tests with pytest\n",
    " - [ ] unit tests with pytest - args\n",
    " - [ ] unit tests with pytest - kwargs\n",
    " - [ ] unit tests with pytest - random generators\n",
    " - [ ] create startup.py to handle project directories and other goodies.\n",
    " - [ ] fix savefig clipping the bottoms of our figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data generator parameters to test\n",
    " 1. All 4 wave variables\n",
    "  - amplitude\n",
    "  - frequency (period)\n",
    "  - offset\n",
    "  - phase\n",
    " 2. sequence length\n",
    " 3. signal noise\n",
    " 4. timestep noise\n",
    " 5. number of signals\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Model hyperparameters to test\n",
    " - `n_timestamps`number of timestamps\n",
    " - `window_size` number of timesteps in sub-sequence window\n",
    " - `n_neurons` number of neurons per LSTM\n",
    " - number of LSTM recurrent cells\n",
    " - number of LSTM layers\n",
    " - `n_epochs` number of epochs\n",
    " - `batch_size`\n",
    " - `window_method` Sliding or Boxcar?\n",
    " - `stateful` True or False?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Questions to answer\n",
    " Q: What would a batch look like?\n",
    " \n",
    " Q: How many LSTM layers do we need? nodes per LSTM layer?\n",
    " \n",
    " Q: Can we learn if our timestamps are not uniformly spaced.\n",
    " \n",
    " Q: Should we make the LSTM layers stateful?\n",
    " \n",
    " Q: Should we use sliding window or boxcar sequences?\n",
    " \n",
    " Q: For stateful LSTM's must we call `model.reset_states()` after any `model.evaluate()` and/or `model.predict()` calls? \n",
    " \n",
    " A: **YES** Ref: Greenlee's book on LSTM's. p.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "from random import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Masking\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_column_matches(data, column='', color='yellow'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_mixed = data == data[column]\n",
    "        return [attr if v else '' for v in is_mixed]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_mixed = data == data[column]\n",
    "        return pd.DataFrame(np.where(is_mixed, attr, ''), index=data.index, columns=data.columns)\n",
    "\n",
    "def get_datetime_now(t=None, fmt='%Y-%m-%d_%H-%M-%S'):\n",
    "    \"\"\"Return timestamp as a string; default: current time, format: YYYY-DD-MM_hh-mm-ss.\"\"\"\n",
    "    if t is None:\n",
    "        t = datetime.now()\n",
    "    return t.strftime(fmt)\n",
    "\n",
    "def plot_stats(csv_filename, columns=['total_reward'], **kwargs):\n",
    "    \"\"\"Plot specified columns from CSV file.\"\"\"\n",
    "    df_stats = pd.read_csv(csv_filename)\n",
    "    df_stats[columns].plot(**kwargs)\n",
    "\n",
    "# Ref http://connor-johnson.com/2014/02/01/smoothing-with-exponentially-weighted-moving-averages/\n",
    "def holt_winters_second_order_ewma(x, span, beta):\n",
    "    N = x.size\n",
    "    alpha = 2.0 / (1 + span)\n",
    "    s = np.zeros((N,))\n",
    "    b = np.zeros((N,))\n",
    "    s[0] = x[0]\n",
    "    for i in range(1, N):\n",
    "        s[i] = alpha * x[i] + (1 - alpha) * (s[i-1] + b[i-1])\n",
    "        b[i] = beta * (s[i] - s[i-1]) + (1 - beta) * b[i-1]\n",
    "    return s\n",
    "\n",
    "def reversed_recombined_holt_winters(x, span=15, beta=0.3):\n",
    "    # take EWMA in both directions with a smaller span term\n",
    "    fwd = holt_winters_second_order_ewma(x, span, beta)\n",
    "    bwd = holt_winters_second_order_ewma(x[::-1], span, beta)\n",
    "    c = np.vstack((fwd, bwd[::-1])) # lump fwd and bwd together\n",
    "    c = np.mean(c, axis=0) # average\n",
    "    return c\n",
    "\n",
    "def save_rnn_layers(hidden_layers, output_layers):\n",
    "    for i, layer in hidden_layers.items():\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), hidden_layers[i]['output'])\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_state'), hidden_layers[i]['state'])\n",
    "#     np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_2_output'), hidden_layers['2']['output'])\n",
    "#     np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_2_state'), hidden_layers['2']['state'])\n",
    "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
    "    \n",
    "def save_mlp_layers(hidden_layers, output_layers):\n",
    "    for i, layer in hidden_layers.items():\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), layer)\n",
    "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
    "    \n",
    "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    \n",
    "    df_confusion = pd.crosstab(y_actu, y_pred.reshape(y_pred.shape[0],), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    \n",
    "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "    \n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)\n",
    "    \n",
    "def glance_at_tensor(tensor):\n",
    "    if len(tensor.shape) == 3:\n",
    "        print(tensor[:10, 0, 0])\n",
    "        print(tensor[0, :10, 0])\n",
    "        print(tensor[0, 0, :10])\n",
    "        print('')\n",
    "        print(tensor[-10:, -1, -1])\n",
    "        print(tensor[-1, -10:, -1])\n",
    "        print(tensor[-1, -1, -10:])\n",
    "    elif len(tensor.shape) == 4:\n",
    "        print(tensor[:10, 0, 0, 0])\n",
    "        print(tensor[0, :10, 0, 0])\n",
    "        print(tensor[0, 0, :10, 0])\n",
    "        print(tensor[0, 0, 0, :10])\n",
    "        print('')\n",
    "        print(tensor[-10:, -1, -1, -1])\n",
    "        print(tensor[-1, -10:, -1, -1])\n",
    "        print(tensor[-1, -1, -10:, -1])\n",
    "        print(tensor[-1, -1, -1, -10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib import stride_tricks\n",
    "\n",
    "def rolling(a, window_size):\n",
    "    shape = (a.size - window_size + 1, window_size)\n",
    "    strides = (a.itemsize, a.itemsize)\n",
    "    return stride_tricks.as_strided(a, shape, strides)\n",
    "\n",
    "window_size = 6\n",
    "Z = np.arange(1, 15, dtype=np.uint32)\n",
    "print(Z.strides)\n",
    "R = rolling(Z, window_size)\n",
    "print(R)\n",
    "\n",
    "print(Z)\n",
    "R = stride_tricks.as_strided(Z, (Z.size - window_size + 1, window_size), (Z.itemsize, Z.itemsize))\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a signal generator\n",
    "\n",
    "The signal generator builds waves using the standard form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$x(t) = A\\sin\\left(2\\pi f t + \\phi\\right) + h$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "where $A$ is the amplitude (vertical scale), $f$ is the frequency (horizontal scale), $\\phi$ is the phase (horizontal offset) and $h$ is the height (vertical offset). This give us fine grained control over how we construct our waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mixsig.mixed import MixedSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# start off with simplest case for proof of concept\n",
    "wave1_coeffs = {\n",
    "    'amplitude': {'mean': 10, 'delta': 2}, \n",
    "    'frequency': {'mean': 1, 'delta': 0.2},\n",
    "    'offset': {'mean': 7.0, 'delta': 2}, \n",
    "    'phase': {'mean': 0, 'delta': 1},\n",
    "    'name': 'A',\n",
    "    'color': '#0000ff'\n",
    "}\n",
    "wave2_coeffs = {\n",
    "    'time': {'t_min': 0, 't_max': 3, 'n_timestamps': 301, 'noise_type': 'pareto', 'pareto_shape': 1.2},\n",
    "    'amplitude': {'mean': 6, 'delta': 1}, \n",
    "    'frequency': {'mean': 4, 'delta': 0.5},\n",
    "    'offset': {'mean': 4.0, 'delta': 1}, \n",
    "    'phase': {'mean': 0, 'delta': 1},\n",
    "    'name': 'B',\n",
    "    'color': '#ff0000'\n",
    "}\n",
    "wave3_coeffs = {\n",
    "    'amplitude': {'mean': 3, 'delta': 0.5}, \n",
    "    'frequency': {'mean': 3, 'delta': 0.5},\n",
    "    'offset': {'mean': 2, 'delta': 0.5}, \n",
    "    'phase': {'mean': 0, 'delta': 1},\n",
    "    'name': 'C',\n",
    "    'color': '#00ff00'\n",
    "}\n",
    "    \n",
    "sigs_coeffs = [wave1_coeffs, wave2_coeffs, wave3_coeffs]\n",
    "\n",
    "msig_coeffs = {\n",
    "#     'amplitude': {'mean': 10, 'delta': 2}, \n",
    "    'frequency': {'mean': 1.0, 'delta': 0}, \n",
    "#     'offset': {'mean': 1, 'delta': 5}\n",
    "    'phase': {'mean': 0, 'delta': 1}, \n",
    "    'time': {'t_min': 0, 't_max': 3, 'n_timestamps': 1000, 'delta': 0}\n",
    "}\n",
    "\n",
    "window_size = 100\n",
    "window_method = ('sliding', 'boxcar')[0]\n",
    "run_label = get_datetime_now()\n",
    "net_type = 'RNN'\n",
    "in_out_model = 'many2many'\n",
    "\n",
    "msig = MixedSignal(\n",
    "    sigs_coeffs, \n",
    "    msig_coeffs, \n",
    "    window_size=window_size, \n",
    "    window_method=window_method, \n",
    "    run_label=run_label,\n",
    "    net_type=net_type,\n",
    "    model=in_out_model\n",
    ")\n",
    "vsig = MixedSignal(\n",
    "    sigs_coeffs, \n",
    "    msig_coeffs, \n",
    "    window_size=window_size, \n",
    "    window_method=window_method, \n",
    "    run_label=run_label,\n",
    "    net_type=net_type,\n",
    "    model=in_out_model\n",
    ")\n",
    "msig.save_config()\n",
    "msig.generate()\n",
    "vsig.generate()\n",
    "n_signals = msig.n_signals\n",
    "print(msig.inputs.shape, msig.labels.shape)\n",
    "print(vsig.inputs.shape, vsig.labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(msig.mixed_signal.itemsize, msig.mixed_signal.strides, msig.mixed_signal.shape)\n",
    "print(msig.one_hots.itemsize, msig.one_hots.strides, msig.one_hots.shape)\n",
    "\n",
    "x_old, y_old = msig.inputs, msig.labels\n",
    "print(x_old.itemsize, x_old.strides, x_old.shape)\n",
    "print(y_old.itemsize, y_old.strides, y_old.shape)\n",
    "\n",
    "# msig.generate_sliding_new()\n",
    "msig.generate_boxcar()\n",
    "\n",
    "x_new, y_new = msig.inputs, msig.labels\n",
    "print(x_new.itemsize, x_new.strides, x_new.shape)\n",
    "print(y_new.itemsize, y_new.strides, y_new.shape)\n",
    "print(x_old.dtype, x_new.dtype)\n",
    "print(y_old.dtype, y_new.dtype)\n",
    "print(np.all(x_old == x_new))\n",
    "print(np.all(y_old == y_new))\n",
    "\n",
    "print(y_old[:, -1])\n",
    "print(y_new[:, -1])\n",
    "print(y_old[-1, :])\n",
    "print(y_new[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.vstack((msig.signals, msig.mixed_signal)).T, index=msig.timestamps, columns=['A', 'B', 'C', 'Mixed'])\n",
    "# signals = np.array([sig() for sig in msig.waves])\n",
    "df = pd.DataFrame(np.vstack((msig.timestamps, msig.signals, msig.mixed_signal)).T, columns=['time', 'A', 'B', 'C', 'Mixed'])\n",
    "df[:10].style.apply(highlight_column_matches, column='Mixed', color='lightblue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "# legend_labels = []\n",
    "# for i in range(msig.n_signals):\n",
    "#     ax.plot(msig.timestamps, msig.signals[i], marker='.', color=msig.signal_colors[i])\n",
    "#     legend_labels.append(msig.signal_names[i])\n",
    "# ax.set_xlim((msig.t_min, msig.t_max))\n",
    "# plt.grid(True)\n",
    "# ax.legend(legend_labels)\n",
    "# plt.savefig(os.path.join(msig.out_dir, 'signals.png'))\n",
    "# plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', marker='.', alpha=0.5)\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "ax.legend([msig.name], loc='upper right', bbox_to_anchor=(0.99, 0.99))\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixedsignal.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.5)\n",
    "y_test_colors = np.hstack([msig.signal_colors[i] for i in msig.classes])\n",
    "ax.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=y_test_colors)\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixedsignal_with_truth.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_neurons = 32\n",
    "n_layers = 1\n",
    "batch_size = 2\n",
    "stateful = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model():\n",
    "    x = Input(shape=(window_size, 1))\n",
    "    h1 = Dense(n_neurons)(x)\n",
    "    h2 = Dense(n_neurons)(h1)\n",
    "    z = Dense(n_signals, activation='softmax')(h2)\n",
    "\n",
    "    model1 = Model(inputs=[x], outputs=[z])\n",
    "    model2 = Model(inputs=[x], outputs=[z, h1, h2])\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model1, model2\n",
    "\n",
    "model, model2 = create_mlp_model()\n",
    "model.summary()\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "# model.add(Masking(mask_value=-1, input_shape=(1,)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(msig.window_size, 1), return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, input_shape=self.input_shape, return_sequences=False, dropout=0.5))\n",
    "# model.add(LSTM(n_neurons, input_shape=(2, 1)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(window_size, 2)))\n",
    "model.add(LSTM(n_neurons, batch_input_shape=(batch_size, window_size, 1), stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(window_size, 1, 1), stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(window_size, 1, 1), stateful=stateful))\n",
    "model.add(LSTM(n_neurons, stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons))\n",
    "# for _ in range(n_layers):\n",
    "#     model.add(LSTM(n_neurons, stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, stateful=stateful))\n",
    "# model.add(Dense(n_signals, activation='softmax'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Reshape((n_neurons, n_signals, 1)))\n",
    "model.add(TimeDistributed(Dense(n_signals, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model():\n",
    "    x = Input(batch_shape=(batch_size, window_size, 1))\n",
    "#     z1 = LSTM(n_neurons, stateful=stateful)(x)\n",
    "    z1, hs1, cs1 = LSTM(n_neurons, stateful=stateful, return_state=True, return_sequences=True)(x)\n",
    "    z2, hs2, cs2 = LSTM(n_neurons, stateful=stateful, return_state=True, return_sequences=True)(z1)\n",
    "#     z2, sh2, sc2 = LSTM(n_neurons, stateful=stateful, return_state=True)(z1)\n",
    "    z = TimeDistributed(Dense(n_signals, activation='softmax'))(z2)\n",
    "#     z = Dense(n_signals, activation='softmax')(z1)\n",
    "\n",
    "    model1 = Model(inputs=[x], outputs=[z])\n",
    "    model2 = Model(inputs=[x], outputs=[z, z1, z2, hs1, cs1, hs2, cs2])\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model1, model2\n",
    "\n",
    "model, model2 = create_rnn_model()\n",
    "model.summary()\n",
    "\n",
    "model_config_filename = os.path.join(msig.out_dir, 'model_config.json')\n",
    "model_summary_filename = os.path.join(msig.out_dir, 'model_plot.png')\n",
    "with open(model_config_filename, 'w') as ofs:\n",
    "    json.dump(json.loads(model.to_json()), ofs, indent=4)\n",
    "plot_model(model, to_file=model_summary_filename, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_generations = 1000\n",
    "n_epochs = 1\n",
    "validate_every = 1\n",
    "save_every = 50\n",
    "\n",
    "model_weights_filename = os.path.join(msig.out_dir, 'model_weights.h5')\n",
    "training_stats_filename = os.path.join(msig.out_dir, 'training_stats.csv')\n",
    "stats = {'gen': [], 'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "x_val, y_val = vsig.generate()\n",
    "n_sequences = msig.n_samples\n",
    "# n_sequences = msig.window_size\n",
    "o_or_s = {0: 'output', 1: 'state'}\n",
    "\n",
    "hidden_layers = {\n",
    "    '1': {\n",
    "        'output': np.zeros((n_generations, n_sequences, n_neurons)), \n",
    "        'state': np.zeros((n_generations, n_sequences, n_neurons))\n",
    "    },\n",
    "    '2': {\n",
    "        'output': np.zeros((n_generations, n_sequences, n_neurons)), \n",
    "        'state': np.zeros((n_generations, n_sequences, n_neurons))\n",
    "    },\n",
    "}\n",
    "\n",
    "# RNN without TimeDistributed\n",
    "# output_layers = np.zeros((n_generations, n_sequences, n_signals))\n",
    "# temp_layers = np.zeros((n_generations, n_sequences, n_neurons))\n",
    "# RNN with TimeDistributed\n",
    "output_layers = np.zeros((n_generations, n_sequences, window_size, n_signals))\n",
    "z1_layers = np.zeros((n_generations, n_sequences, window_size, n_neurons))\n",
    "z2_layers = np.zeros((n_generations, n_sequences, window_size, n_neurons))\n",
    "\n",
    "for i in range(n_generations):\n",
    "    x_train, y_train = msig.generate()    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=n_epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(x_val, y_val),\n",
    "        verbose=1, \n",
    "        shuffle=False\n",
    "    )\n",
    "    if stateful:\n",
    "        model.reset_states()\n",
    "    \n",
    "    stats['gen'].append(i + 1)\n",
    "    stats['loss'].append(history.history['loss'][-1])\n",
    "    stats['acc'].append(history.history['acc'][-1])\n",
    "    stats['val_loss'].append(history.history['val_loss'][-1])\n",
    "    stats['val_acc'].append(history.history['val_acc'][-1])\n",
    "    \n",
    "    if (i + 1) % validate_every == 0:\n",
    "        y_hat, z1, z2, *args = model2.predict(x_val, batch_size=batch_size)\n",
    "        if stateful:\n",
    "            model2.reset_states()\n",
    "        output_layers[i] = y_hat#.reshape(n_subsequences, n_signals)\n",
    "        z1_layers[i] = z1\n",
    "        z2_layers[i] = z2\n",
    "        for j, state in enumerate(args):\n",
    "            layer = str((j // 2) + 1)\n",
    "            o_or_s_flag = o_or_s[j % 2]\n",
    "            hidden_layers[layer][o_or_s_flag][i] = state\n",
    "\n",
    "    if (i + 1) % save_every == 0:\n",
    "        print('#' * 50)\n",
    "        print('Generation: ', (i + 1))\n",
    "        print('#' * 50)\n",
    "        model.save_weights(model_weights_filename)\n",
    "        df_stats = pd.DataFrame.from_dict(stats)\n",
    "        df_stats.to_csv(training_stats_filename, mode='w', index=False, header=True)\n",
    "        save_rnn_layers(hidden_layers, output_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_generations = 1000\n",
    "n_epochs = 1\n",
    "validate_every = 1\n",
    "save_every = 50\n",
    "\n",
    "model_weights_filename = os.path.join(msig.out_dir, 'model_weights.h5')\n",
    "training_stats_filename = os.path.join(msig.out_dir, 'training_stats.csv')\n",
    "stats = {'gen': [], 'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "x_val, y_val = vsig.generate()\n",
    "n_sequences = msig.n_samples\n",
    "# n_sequences = msig.window_size\n",
    "\n",
    "# output_layers = np.zeros((n_generations, n_sequences, n_signals))\n",
    "# hidden_layers = {\n",
    "#     '1': np.zeros((n_generations, n_sequences, n_neurons)),\n",
    "# }\n",
    "output_layers = np.zeros((n_generations, n_sequences, window_size, n_signals))\n",
    "hidden_layers = {\n",
    "    '1': np.zeros((n_generations, n_sequences, window_size, n_neurons)),\n",
    "    '2': np.zeros((n_generations, n_sequences, window_size, n_neurons)),\n",
    "}\n",
    "\n",
    "for i in range(n_generations):\n",
    "    x_train, y_train = msig.generate()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=n_epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(x_val, y_val),\n",
    "        verbose=1, \n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    stats['gen'].append(i + 1)\n",
    "    stats['loss'].append(history.history['loss'][-1])\n",
    "    stats['acc'].append(history.history['acc'][-1])\n",
    "    stats['val_loss'].append(history.history['val_loss'][-1])\n",
    "    stats['val_acc'].append(history.history['val_acc'][-1])\n",
    "    \n",
    "    if (i + 1) % validate_every == 0:\n",
    "        y_hat, *args = model2.predict(x_val, batch_size=batch_size)\n",
    "        output_layers[i] = y_hat\n",
    "        for j, layer in enumerate(args):\n",
    "            hidden_layers[str(j + 1)][i] = layer\n",
    "\n",
    "    if (i + 1) % save_every == 0:\n",
    "        print('#' * 50)\n",
    "        print('Generation: ', i + 1)\n",
    "        print('#' * 50)\n",
    "        model.save_weights(model_weights_filename)\n",
    "        df_stats = pd.DataFrame.from_dict(stats)\n",
    "        df_stats.to_csv(training_stats_filename, mode='w', index=False, header=True)\n",
    "        save_mlp_layers(hidden_layers, output_layers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new test signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "if stateful:\n",
    "    model.reset_states()\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "if stateful:\n",
    "    model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=-1)\n",
    "y_pred_colors = np.hstack([msig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "print(score)\n",
    "\n",
    "if window_method == 'boxcar' and net_type == 'RNN':\n",
    "    x_test_x_scatter = msig.timestamps\n",
    "    x_test_y_scatter = msig.mixed_signal\n",
    "    x_windows_start = np.reshape(msig.timestamps, y_pred.shape)[:, 0]\n",
    "elif window_method == 'boxcar' and net_type == 'MLP' and in_out_model == 'many2many':\n",
    "    x_test_x_scatter = msig.timestamps\n",
    "    x_test_y_scatter = msig.mixed_signal\n",
    "    x_windows_start = np.reshape(msig.timestamps, y_pred.shape)[:, 0]\n",
    "elif window_method == 'sliding':\n",
    "    x_test_x_scatter = msig.timestamps[msig.window_size-1:]\n",
    "    x_test_y_scatter = msig.mixed_signal[msig.window_size-1:]\n",
    "#     x_test_y_scatter = x_test[:, -1, 0]\n",
    "#     x_test_y_scatter = x_test[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(msig.classes, y_pred.flatten()))\n",
    "plot_confusion_matrix(msig.classes, y_pred.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## current validation signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size)\n",
    "if stateful:\n",
    "    model.reset_states()\n",
    "y_hat = model.predict(x_val, batch_size=batch_size)\n",
    "if stateful:\n",
    "    model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=-1)\n",
    "y_pred_colors = np.hstack([vsig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "print(score)\n",
    "\n",
    "if window_method == 'boxcar':\n",
    "    x_test_x_scatter = vsig.timestamps\n",
    "    x_test_y_scatter = vsig.mixed_signal\n",
    "    x_windows_start = np.reshape(vsig.timestamps, y_pred.shape)[:, 0]\n",
    "elif window_method == 'sliding':\n",
    "    x_test_x_scatter = vsig.timestamps[vsig.window_size-1:]\n",
    "    x_test_y_scatter = vsig.mixed_signal[vsig.window_size-1:]\n",
    "#     x_test_y_scatter = x_test[:, -1, 0]\n",
    "#     x_test_y_scatter = x_test[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(x_test[:2])\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_test_y_scatter.shape)\n",
    "print(x_test_y_scatter[:15])\n",
    "\n",
    "print(y_hat.shape)\n",
    "print(y_hat[:2])\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_pred[:2])\n",
    "\n",
    "print(y_pred_colors.shape)\n",
    "print(y_pred_colors[:2*y_pred.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "ax1 = plt.subplot2grid((5, 4), (0, 0), colspan=2, rowspan=3)\n",
    "ax2 = plt.subplot2grid((5, 4), (0, 2), colspan=2, rowspan=3)\n",
    "ax3 = plt.subplot2grid((5, 4), (3, 0), colspan=4, rowspan=2)\n",
    "\n",
    "ax1.plot(df_stats.loss, alpha=0.3)\n",
    "ax1.plot(df_stats.val_loss, alpha=0.3)\n",
    "\n",
    "hw_loss = reversed_recombined_holt_winters(np.array(df_stats.loss))\n",
    "hw_val_loss = reversed_recombined_holt_winters(np.array(df_stats.val_loss))\n",
    "ax1.plot(hw_loss)\n",
    "ax1.plot(hw_val_loss)\n",
    "\n",
    "ax1.set_title(r'timestamps = {}, timesteps = {}'.format(msig.n_timestamps, msig.window_size))\n",
    "ax1.set_xlabel(r'generation')\n",
    "ax1.set_xlim((0, n_generations))\n",
    "ax1.set_ylabel(r'loss')\n",
    "ax1.set_ylim((0, None))\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(df_stats.acc, alpha=0.3)\n",
    "ax2.plot(df_stats.val_acc, alpha=0.3)\n",
    "\n",
    "hw_acc = reversed_recombined_holt_winters(np.array(df_stats.acc))\n",
    "hw_val_acc = reversed_recombined_holt_winters(np.array(df_stats.val_acc))\n",
    "ax2.plot(hw_acc)\n",
    "ax2.plot(hw_val_acc)\n",
    "\n",
    "ax2.set_title(r'neurons = {}, batch_size = {}'.format(n_neurons, batch_size))\n",
    "ax2.set_xlabel(r'generation')\n",
    "ax2.set_xlim((0, n_generations))\n",
    "ax2.set_ylabel(r'accuracy')\n",
    "ax2.set_ylim((0, 1))\n",
    "ax2.grid(True)\n",
    "\n",
    "ax3.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax3.scatter(x_test_x_scatter, x_test_y_scatter, marker='.', c=y_pred_colors)\n",
    "if window_method == 'boxcar' and msig.n_samples <= 20:\n",
    "    ax3.vlines(x_windows_start, min(msig.mixed_signal), max(msig.mixed_signal))\n",
    "ax3.set_title('window = {}, loss = {:<6.4f}, accuracy = {:<6.4f}'.format(window_method, *score))\n",
    "ax3.set_xlabel('time')\n",
    "ax3.set_xlim((msig.t_min, msig.t_max))\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(msig.out_dir, 'loss_acc.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape)\n",
    "print(hidden_layers['1'].shape)\n",
    "print(output_layers.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape)\n",
    "print(hidden_layers['1']['output'].shape)\n",
    "print(hidden_layers['1']['state'].shape)\n",
    "print(z1_layers.shape)\n",
    "print(output_layers.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.reshape(z2_layers[..., 5], (1000, 1000))\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "im = ax.imshow(arr, interpolation=\"none\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(msig.out_dir, 'gen_loss_acc.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = '1'\n",
    "o_or_s = 'output'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\n",
    "print(val_arrays.shape)\n",
    "glance_at_tensor(val_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/maddoxw/PycharmProjects/MixSig/out/2018-04-09_04-53-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_arrays = np.load(os.path.join(vsig.out_dir, 'valid_output_layer.npy'))\n",
    "print(val_arrays.shape)\n",
    "glance_at_tensor(val_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_hat = model.predict(x_val, batch_size=batch_size)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(states['y_hat'], axis=1)\n",
    "# y_pred_colors = np.hstack([vsig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "layer = '1'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + layer + '_output.npy'))\n",
    "n_generations, _, n_neurons = val_arrays.shape\n",
    "ncols = 1\n",
    "nrows = n_neurons // ncols\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 3))\n",
    "\n",
    "for g in range(n_generations):\n",
    "    for i in range(n_neurons):\n",
    "        ax = axes#[i // ncols, i % ncols]\n",
    "        ax.cla()\n",
    "        y_pred_colors = val_arrays[g, :, i]\n",
    "        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n",
    "        ax.scatter(\n",
    "            vsig.timestamps[vsig.window_size-1:], \n",
    "#             vsig.timestamps, \n",
    "#             x_val[:, -1, 0], \n",
    "#             x_val[0, :, 0], \n",
    "            vsig.mixed_signal[vsig.window_size-1:], \n",
    "            marker='o', \n",
    "            c=y_pred_colors, \n",
    "            cmap=plt.get_cmap('coolwarm'), \n",
    "            vmin=-1, \n",
    "            vmax=1\n",
    "        )\n",
    "        ax.set_title('neuron = {}'.format(i + 1))\n",
    "        ax.set_xlim((vsig.t_min, vsig.t_max))\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, 'output', g + 1))\n",
    "#     plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, 'gen', str(g + 1)]) + '.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(states['y_hat'], axis=1)\n",
    "# y_pred_colors = np.hstack([vsig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "layer = '2'\n",
    "o_or_s = 'output'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\n",
    "n_generations, _, n_neurons = val_arrays.shape\n",
    "ncols = 2\n",
    "nrows = n_neurons // ncols\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 20))\n",
    "\n",
    "for g in range(n_generations):\n",
    "    for i in range(n_neurons):\n",
    "        ax = axes[i // ncols, i % ncols]\n",
    "        ax.cla()\n",
    "        y_pred_colors = val_arrays[g, :, i]\n",
    "        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n",
    "        ax.scatter(\n",
    "#             vsig.timestamps[vsig.window_size-1:], \n",
    "            vsig.timestamps, \n",
    "#             x_val[:, -1, 0], \n",
    "            x_val[0, :, 0], \n",
    "            vsig.timestamps[vsig.window_size-1:], \n",
    "            marker='o', \n",
    "            c=y_pred_colors, \n",
    "            cmap=plt.get_cmap('coolwarm'), \n",
    "            vmin=-1, \n",
    "            vmax=1\n",
    "        )\n",
    "        ax.set_title('neuron = {}'.format(i + 1))\n",
    "        ax.set_xlim((vsig.t_min, vsig.t_max))\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, o_or_s, g + 1))\n",
    "    plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s, 'gen', str(g + 1)]) + '.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "y_hat, *args = model2.predict(x_test, batch_size=batch_size)\n",
    "model2.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=-1)\n",
    "print('x_test', x_test.shape, '{:>9.4f} {:>9.4f}'.format(np.min(x_test), np.max(x_test)))\n",
    "print('y_test', y_test.shape)\n",
    "print('y_hat ', y_hat.shape, '{:>9.4f} {:>9.4f}'.format(np.min(y_hat), np.max(y_hat)))\n",
    "print('y_pred', y_pred.shape, '{} {}'.format(np.min(y_pred), np.max(y_pred)))\n",
    "for i, arg in enumerate(args):\n",
    "    print(i, arg.shape, '{:>9.4f} {:>9.4f}'.format(np.min(arg), np.max(arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_colors = np.hstack([msig.signal_colors[i] for i in y_pred])\n",
    "print(y_pred_colors[:3])\n",
    "print(y_pred.shape, y_pred_colors.shape)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "# ax.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred_colors)\n",
    "# ax.scatter(msig.timestamps, x_test[0, :, 0], marker='.', c=y_pred_colors)\n",
    "ax.scatter(msig.timestamps[msig.window_size-1:], msig.mixed_signal[msig.window_size-1:], marker='.', c=y_pred_colors)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "# y_pred = model.predict_classes(x_test, batch_size=batch_size)\n",
    "# y_pred_colors = [msig.waves[i].color for i in msig.classes[msig.window_size-1:]]\n",
    "y_pred_colors = np.hstack([msig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred_colors)\n",
    "ax.set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax.set_xlabel('time')\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'eval_pred.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "print(score)\n",
    "\n",
    "y_pred = model.predict_classes(x_test, batch_size=batch_size)\n",
    "# y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "# y_pred = np.argmax(y_hat, axis=1)\n",
    "# y_error = 1.0 - np.max(y_hat, axis=1)\n",
    "model.reset_states()\n",
    "# print(y_hat.shape)\n",
    "print(y_pred.shape)\n",
    "# print(y_error.shape)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 6))\n",
    "\n",
    "ax[0].plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax[0].scatter(msig.timestamps, msig.mixed_signal, marker='.')\n",
    "ax[0].set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax[0].set_xlim((msig.t_min, msig.t_max))\n",
    "\n",
    "ax[1].plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "ax[1].scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "ax[1].set_xlim((msig.t_min, msig.t_max))\n",
    "ax[1].set_xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer weights to new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_batch = 1\n",
    "print(X.shape)\n",
    "print(n_batch)\n",
    "# re-define model\n",
    "new_model = Sequential()\n",
    "new_model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
    "new_model.add(LSTM(n_neurons))\n",
    "new_model.add(Dense(msig.n_signals, activation='softmax'))\n",
    "# copy weights\n",
    "old_weights = model.get_weights()\n",
    "new_model.set_weights(old_weights)\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "x_test, y_test = msig.generate()\n",
    "score = new_model.evaluate(x_test, y_test, batch_size=n_batch)\n",
    "print(score)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=msig.one_hots)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "for i in range(len(x_test)):\n",
    "    print('Expected', y_test[i], 'Predicted', y_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "print(y_hat.shape)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "print(y_pred.shape)\n",
    "y_error = np.max(y_hat, axis=1)\n",
    "print(y_error.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_error)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[-msig.n_samples:], y_error, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[-msig.n_samples:], y_error, marker='.', c=y_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeDistributed testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-One LSTM for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(length, 1, 1)\n",
    "y = seq.reshape(length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = length\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "# print(X)\n",
    "# print(result)\n",
    "for value in result:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-One LSTM for Sequence Prediction (without TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1)))\n",
    "model.add(Dense(length))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "print(X)\n",
    "print(result)\n",
    "for value in result[0,:]:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many LSTM for Sequence Prediction (with TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 19\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = 5\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many LSTM for Sequence Prediction (without TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 19\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = 5\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1), return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "for x, value in zip(X[0, :, 0], result[0, :, 0]):\n",
    "    print('{:>.2f} {:>.3f}'.format(x, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "for x, value in zip(X[0, :, 0], result[0, :, 0]):\n",
    "    print('{:>.2f} {:>.3f}'.format(x, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "    return pd.datetime.strptime('190'+x, '%Y-%m')\n",
    "series = pd.read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "print(series.head())\n",
    "# transform to be stationary\n",
    "differenced = difference(series, 1)\n",
    "print(differenced.head())\n",
    "# invert transform\n",
    "inverted = list()\n",
    "for i in range(len(differenced)):\n",
    "    value = inverse_difference(series, differenced[i], len(series)-i)\n",
    "    inverted.append(value)\n",
    "inverted = pd.Series(inverted)\n",
    "print(inverted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # this example is too small to use anything larger than 1.\n",
    "window_size = 7  # This is the size after unrolling.\n",
    "n_features = 1  # Assume each red square represents a single number.\n",
    "n_layers = 3  # These are the middle 3 horizontal layers.\n",
    "n_neurons = 2  # One neuron for the green block(s) and one for the yellow.\n",
    "n_outputs = 7  # because it's many to many.\n",
    "\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "\n",
    "x = Input(batch_shape=(batch_size, window_size, n_features))  # bottom row of red blocks.\n",
    "h = LSTM(n_neurons, return_sequences=True)(x)  # hidden layer 1\n",
    "h = LSTM(n_neurons, return_sequences=True)(h)  # hidden layer 2\n",
    "h = LSTM(n_neurons, return_sequences=True)(h)  # hidden layer 3\n",
    "z = TimeDistributed(Dense(n_outputs, activation='softmax'))(h)  # top row of blue blocks\n",
    "model = Model(inputs=[x],outputs=[z])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "import numpy\n",
    "from numpy import concatenate\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    return df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "    diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "    new_row = [x for x in X] + [yhat]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    "\n",
    "# run a repeated experiment\n",
    "def experiment(repeats, series):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series.values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, 1)\n",
    "    supervised_values = supervised.values[1:,:]\n",
    "    # split data into train and test-sets\n",
    "    train, test = supervised_values[0:-12, :], supervised_values[-12:, :]\n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(repeats):\n",
    "        # fit the base model\n",
    "        lstm_model = fit_lstm(train_scaled, 1, 1000, 1)\n",
    "        # forecast test dataset\n",
    "        predictions = list()\n",
    "        for i in range(len(test_scaled)):\n",
    "            # predict\n",
    "            X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "            yhat = forecast_lstm(lstm_model, 1, X)\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores\n",
    "\n",
    "# execute the experiment\n",
    "def run():\n",
    "    # load dataset\n",
    "    series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "    # experiment\n",
    "    repeats = 10\n",
    "    results = DataFrame()\n",
    "    # run experiment\n",
    "    results['results'] = experiment(repeats, series)\n",
    "    # summarize results\n",
    "    print(results.describe())\n",
    "    # save results\n",
    "    results.to_csv('experiment_stateful.csv', index=False)\n",
    "\n",
    " # entry point\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=True, shuffle=False\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=False, shuffle=False\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=False, shuffle=True\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load results into a dataframe\n",
    "filenames = ['experiment_stateful.csv', 'experiment_stateful2.csv']\n",
    "results = DataFrame()\n",
    "for name in filenames:\n",
    "    results[name[11:-4]] = read_csv(name, header=0)\n",
    "# describe all results\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load results into a dataframe\n",
    "filenames = ['experiment_stateful.csv', 'experiment_stateless.csv', 'experiment_stateless_shuffle.csv']\n",
    "results = DataFrame()\n",
    "for name in filenames:\n",
    "    results[name[11:-4]] = read_csv(name, header=0)\n",
    "# describe all results\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "results.boxplot()\n",
    "pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
