{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MixSig\n",
    "## Option 1\n",
    "Create a model that reads a sequence of numbers, one number at a time, and classify that number based on all previously seen numbers.\n",
    "\n",
    "## Option 2\n",
    "Create a model that reads a sequence of numbers and classifies the last number in the sequence based on the previous numbers in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How this project is useful\n",
    " 1. full control over dataset\n",
    " 2. infinite dataset\n",
    " 3. can study all three RNN base problems (classification, prediction, forcasting).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Project Steps\n",
    " 1. create dataset\n",
    " 2. create network\n",
    " 3. train network\n",
    " 4. test network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## TODO\n",
    " - [+] create single signal generator class - A single standalone wave.\n",
    " - [+] create mixed signal generator class - Choose from one wave per timestamp.\n",
    " - [ ] create multi signal generator class - Superposition of multiple waves.\n",
    " - [+] create signal noise functions (Gaussian, etc.)\n",
    " - [+] create timestep noise functions \n",
    " - [+] add legends to plots.\n",
    " - [ ] during training, save outlier X, y train sets to file for further analysis.\n",
    " - [+] save configuration of mixed signal properties as json.\n",
    " - [ ] make plots of the mixed signal with colors mapped to hidden layers, lstm states, etc.\n",
    " - [ ] unit tests with pytest\n",
    " - [ ] unit tests with pytest - args\n",
    " - [ ] unit tests with pytest - kwargs\n",
    " - [ ] unit tests with pytest - random generators\n",
    " - [+] create `startup.py` to handle project directories and other goodies.\n",
    " - [+] fix savefig clipping the bottoms of our figures.\n",
    " - [ ] change `MixedSignal.mixed_signal` to `MixedSignal.inputs`\n",
    " - [ ] come up with a case where the input has 1 feature and output has 1 class.\n",
    "  - This is a binary classification task. (Where do waves from a mix sig overlap?)\n",
    " - [ ] come up with a case where the input has 1 feature and output has 2+ classes.\n",
    "  - Classify the last number in the sequence based on the rest of the sequence.\n",
    " - [ ] come up with a case where the input has 2+ features and output has 1 class.\n",
    "  - Calculate the derivative of each wave and make a new mixed_deriv to go with mixed_signal.\n",
    " - [ ] come up with a case where the input has 2+ features and output has 2+ classes.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data generator parameters to test\n",
    " 1. All 4 wave variables\n",
    "  - amplitude\n",
    "  - frequency (period)\n",
    "  - offset\n",
    "  - phase\n",
    " 2. sequence length\n",
    " 3. signal noise\n",
    " 4. timestep noise\n",
    " 5. number of signals\n",
    " 6. types of signals (single, mixed, multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Model hyperparameters to test\n",
    " - `n_timestamps`number of timestamps\n",
    " - `window_size` number of timesteps in sub-sequence window\n",
    " - `n_neurons` number of neurons per LSTM\n",
    " - number of LSTM recurrent cells\n",
    " - number of LSTM layers\n",
    " - `n_epochs` number of epochs\n",
    " - `batch_size`\n",
    " - `window_type` Sliding or Boxcar?\n",
    " - `stateful` True or False?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Questions to answer\n",
    " Q: What would a batch look like?\n",
    " \n",
    " Q: How many LSTM layers do we need? nodes per LSTM layer?\n",
    " \n",
    " Q: Can we learn if our timestamps are not uniformly spaced.\n",
    " \n",
    " Q: Should we make the LSTM layers stateful?\n",
    " \n",
    " Q: Should we use sliding window or boxcar sequences?\n",
    " \n",
    " Q: For stateful LSTM's must we call `model.reset_states()` after any `model.evaluate()` and/or `model.predict()` calls? \n",
    " \n",
    " A: **YES** Ref: Greenlee's book on LSTM's. p.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Add\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Masking\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from mixsig.mixed import MixedSignal\n",
    "from mixsig.plot_utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/maddoxw/git/PhasedLSTM-Keras')\n",
    "from phased_lstm_keras.PhasedLSTM import PLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "BIGGEST_SIZE = 20\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_column_matches(data, column='', color='yellow'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_mixed = data == data[column]\n",
    "        return [attr if v else '' for v in is_mixed]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_mixed = data == data[column]\n",
    "        return pd.DataFrame(np.where(is_mixed, attr, ''), index=data.index, columns=data.columns)\n",
    "\n",
    "def plot_stats(csv_filename, columns=['total_reward'], **kwargs):\n",
    "    \"\"\"Plot specified columns from CSV file.\"\"\"\n",
    "    df_stats = pd.read_csv(csv_filename)\n",
    "    df_stats[columns].plot(**kwargs)\n",
    "\n",
    "# Ref http://connor-johnson.com/2014/02/01/smoothing-with-exponentially-weighted-moving-averages/\n",
    "def holt_winters_second_order_ewma(x, span, beta):\n",
    "    N = x.size\n",
    "    alpha = 2.0 / (1 + span)\n",
    "    s = np.zeros((N,))\n",
    "    b = np.zeros((N,))\n",
    "    s[0] = x[0]\n",
    "    for i in range(1, N):\n",
    "        s[i] = alpha * x[i] + (1 - alpha) * (s[i-1] + b[i-1])\n",
    "        b[i] = beta * (s[i] - s[i-1]) + (1 - beta) * b[i-1]\n",
    "    return s\n",
    "\n",
    "def reversed_recombined_holt_winters(x, span=15, beta=0.3):\n",
    "    # take EWMA in both directions with a smaller span term\n",
    "    fwd = holt_winters_second_order_ewma(x, span, beta)\n",
    "    bwd = holt_winters_second_order_ewma(x[::-1], span, beta)\n",
    "    c = np.vstack((fwd, bwd[::-1])) # lump fwd and bwd together\n",
    "    c = np.mean(c, axis=0) # average\n",
    "    return c\n",
    "\n",
    "def save_rnn_layers(hidden_layers, output_layers):\n",
    "    for i, layer in hidden_layers.items():\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), hidden_layers[i]['output'])\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_state'), hidden_layers[i]['state'])\n",
    "#     np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_2_output'), hidden_layers['2']['output'])\n",
    "#     np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_2_state'), hidden_layers['2']['state'])\n",
    "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
    "    \n",
    "def save_mlp_layers(hidden_layers, output_layers):\n",
    "    for i, layer in hidden_layers.items():\n",
    "        np.save(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + i + '_output'), layer)\n",
    "    np.save(os.path.join(vsig.out_dir, 'valid_output_layer'), output_layers)\n",
    "    \n",
    "def glance_at_tensor(tensor):\n",
    "    if len(tensor.shape) == 3:\n",
    "        print(tensor[:10, 0, 0])\n",
    "        print(tensor[0, :10, 0])\n",
    "        print(tensor[0, 0, :10])\n",
    "        print('')\n",
    "        print(tensor[-10:, -1, -1])\n",
    "        print(tensor[-1, -10:, -1])\n",
    "        print(tensor[-1, -1, -10:])\n",
    "    elif len(tensor.shape) == 4:\n",
    "        print(tensor[:10, 0, 0, 0])\n",
    "        print(tensor[0, :10, 0, 0])\n",
    "        print(tensor[0, 0, :10, 0])\n",
    "        print(tensor[0, 0, 0, :10])\n",
    "        print('')\n",
    "        print(tensor[-10:, -1, -1, -1])\n",
    "        print(tensor[-1, -10:, -1, -1])\n",
    "        print(tensor[-1, -1, -10:, -1])\n",
    "        print(tensor[-1, -1, -1, -10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build a signal generator\n",
    "\n",
    "The signal generator builds waves using the standard form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$x(t) = A\\sin\\left(2\\pi f t + \\phi\\right) + h$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "where $A$ is the amplitude (vertical scale), $f$ is the frequency (horizontal scale), $\\phi$ is the phase (horizontal offset) and $h$ is the height (vertical offset). This give us fine grained control over how we construct our waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start off with simplest case for proof of concept\n",
    "wave1_coeffs = {\n",
    "    'amplitude': {'mean': 0.5, 'delta': 0.05}, \n",
    "    'frequency': {'mean': 1.0, 'delta': 0.1},\n",
    "    'offset': {'mean': 0.0, 'delta': 0.1}, \n",
    "    'phase': {'mean': 0.0, 'delta': 1.0},\n",
    "    'name': 'A',\n",
    "    'color': '#0000ff'\n",
    "}\n",
    "wave2_coeffs = {\n",
    "    'amplitude': {'mean': 0.75, 'delta': 0.075}, \n",
    "    'frequency': {'mean': 3.0, 'delta': 0.3},\n",
    "    'offset': {'mean': 0.0, 'delta': 0.1}, \n",
    "    'phase': {'mean': 0.0, 'delta': 1.0},\n",
    "    'name': 'B',\n",
    "    'color': '#ff0000',\n",
    "#     'time': {'t_min': 0, 't_max': 5, 'n_timestamps': 601, 'noise_type': 'pareto', 'pareto_shape': 1.3},\n",
    "}\n",
    "wave3_coeffs = {\n",
    "    'amplitude': {'mean': 1.0, 'delta': 0.1}, \n",
    "    'frequency': {'mean': 8.0, 'delta': 0.8},\n",
    "    'offset': {'mean': 0.0, 'delta': 0.2}, \n",
    "    'phase': {'mean': 0.0, 'delta': 1.0},\n",
    "    'name': 'C',\n",
    "    'color': '#00ff00'\n",
    "}\n",
    "\n",
    "mwave_coeffs = {\n",
    "    'amplitude': {'mean': 1.0, 'delta': 0}, \n",
    "    'frequency': {'mean': 1.0, 'delta': 0}, \n",
    "    'offset': {'mean': 0, 'delta': 0},\n",
    "    'phase': {'mean': 0, 'delta': 1}, \n",
    "    'name': 'mixed_wave',\n",
    "    'time': {'t_min': 0, 't_max': 2, 'n_timestamps': 4096, 'delta': 0}\n",
    "}\n",
    "\n",
    "sigs_coeffs = [wave1_coeffs, wave2_coeffs, wave3_coeffs, mwave_coeffs]\n",
    "\n",
    "features=('x', 'dxdt')\n",
    "batch_size = 1\n",
    "window_size = 4096\n",
    "window_type = 'sliding'\n",
    "network_type = 'TCN'\n",
    "sequence_type = 'many2many'\n",
    "n_groups = 5\n",
    "\n",
    "msig = MixedSignal(\n",
    "    sigs_coeffs, \n",
    "    *features,\n",
    "#     batch_size=batch_size,\n",
    "    window_size=window_size, \n",
    "    window_type=window_type, \n",
    "    network_type=network_type,\n",
    "    sequence_type=sequence_type,\n",
    "    n_groups=n_groups\n",
    ")\n",
    "\n",
    "msig.generate()\n",
    "n_classes = msig.n_classes\n",
    "n_features = msig.n_features\n",
    "input_shape = (window_size, n_features) # RNN\n",
    "input_shape = (None, n_features) # TCN\n",
    "\n",
    "print(msig.inputs.shape)\n",
    "print(msig.mixed_signal.shape)\n",
    "print(msig.one_hots.shape)\n",
    "print(msig.labels.shape)\n",
    "print(msig.n_timestamps)\n",
    "print(msig.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.vstack((msig.waves, msig.mixed_signal)).T, index=msig.timestamps, columns=['A', 'B', 'C', 'Mixed'])\n",
    "waves = np.array([sig.generate(msig.timestamps) for sig in msig.waves])\n",
    "df = pd.DataFrame(np.vstack((msig.timestamps, waves, msig.mixed_signal)).T, columns=['time', 'A', 'B', 'C', 'Mixed'])\n",
    "df[:10].style.apply(highlight_column_matches, column='Mixed', color='lightblue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "msig.save_config()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "legend_labels = []\n",
    "for wave in msig.waves:\n",
    "    ax.plot(wave.timestamps, wave.sample, marker='.', color=wave.color)\n",
    "    legend_labels.append(wave.name)\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "ax.legend(legend_labels)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'all_waves_with_truth.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.scatter(msig.timestamps, msig.mixed_signal, color='grey', marker='.', alpha=0.5)\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "ax.legend([msig.name], loc='upper right', bbox_to_anchor=(0.99, 0.99))\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixed_signal.png'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.5)\n",
    "y_test_colors = np.hstack([msig.waves[i].color for i in msig.labels])\n",
    "ax.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=y_test_colors)\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mixed_signal_with_truth.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Generate dummy data\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "# model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_neurons = 32\n",
    "kernel_size = 3\n",
    "stateful = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = msig.input_shape\n",
    "x = Input(shape=input_shape)\n",
    "h1 = Conv1D(8, dilation_rate=1, input_shape=input_shape, **conv1d_kwargs)(x)\n",
    "h2 = Conv1D(8, dilation_rate=2, input_shape=input_shape, **conv1d_kwargs)(h1)\n",
    "z = Dense(n_classes, activation='sigmoid')(h2)\n",
    "model = Model(inputs=[x], outputs=[z])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=input_shape)\n",
    "h1 = Dense(n_neurons, activation='relu')(x)\n",
    "h2 = Dense(n_neurons, activation='relu')(h1)\n",
    "z = Dense(msig.n_classes, activation='softmax')(h2)\n",
    "model = Model(inputs=[x], outputs=[z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = 'binary'\n",
    "input_shape = (10, 5)\n",
    "conv1d_kwargs = dict(kernel_size=kernel_size, padding='causal', activation='relu')\n",
    "compile_kwargs = dict(loss=class_type+'_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(8, dilation_rate=1, input_shape=input_shape, **conv1d_kwargs))\n",
    "if class_type == 'binary':\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "else:\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(**compile_kwargs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_layer(x, n_neurons, dilation_rate, conv1d_kwargs, dropout=0, normalize=False):\n",
    "    h = Conv1D(n_neurons, dilation_rate=dilation_rate, **conv1d_kwargs)(x)\n",
    "    if normalize:\n",
    "        h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    if dropout:\n",
    "        h = Dropout(dropout)(h)\n",
    "    return h\n",
    "\n",
    "def temporal_block(h0, n_neurons, dilation_rate, conv1d_kwargs, dropout=0, normalize=False):\n",
    "    h1 = temporal_layer(h0, n_neurons, dilation_rate, conv1d_kwargs, dropout=dropout, normalize=normalize)\n",
    "    h2 = temporal_layer(h1, n_neurons, dilation_rate, conv1d_kwargs, dropout=dropout, normalize=normalize)\n",
    "    res = Conv1D(n_neurons, kernel_size=1)(h0) if h0.shape != h2.shape else h0        \n",
    "    block = Add()([res, h2])\n",
    "    return Activation('relu')(block)\n",
    "\n",
    "print(input_shape)\n",
    "conv1d_kwargs = dict(kernel_size=kernel_size, padding='causal')\n",
    "\n",
    "x = Input(shape=input_shape)\n",
    "h = temporal_layer(x, n_neurons, 1, conv1d_kwargs)\n",
    "# h = temporal_block(x, n_neurons, 1, conv1d_kwargs)\n",
    "for d in range(1, 11):\n",
    "    h = temporal_layer(h, n_neurons, 2**d, conv1d_kwargs)\n",
    "#     h = temporal_block(h, n_neurons, 2**d, conv1d_kwargs)\n",
    "z = Dense(n_classes, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[x], outputs=[z])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_shape)\n",
    "conv1d_kwargs = dict(kernel_size=kernel_size, padding='causal')\n",
    "model = Sequential()\n",
    "model.add(Conv1D(n_neurons, dilation_rate=1, input_shape=input_shape, **conv1d_kwargs))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "for d in range(1, 11):\n",
    "    model.add(Conv1D(n_neurons, dilation_rate=2**d, **conv1d_kwargs))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "# model.add(Masking(mask_value=-1, input_shape=(1,)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(msig.window_size, 1), return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, input_shape=self.input_shape, return_sequences=False, dropout=0.5))\n",
    "# model.add(LSTM(n_neurons, input_shape=(2, 1)))\n",
    "# model.add(LSTM(n_neurons, input_shape=(window_size, 2)))\n",
    "model.add(LSTM(n_neurons, batch_input_shape=(batch_size, window_size, 1), stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(window_size, 1, 1), stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, batch_input_shape=(window_size, 1, 1), stateful=stateful))\n",
    "model.add(LSTM(n_neurons, stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons))\n",
    "# for _ in range(n_layers):\n",
    "#     model.add(LSTM(n_neurons, stateful=stateful, return_sequences=True))\n",
    "# model.add(LSTM(n_neurons, stateful=stateful))\n",
    "# model.add(Dense(n_classes, activation='softmax'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Reshape((n_neurons, n_classes, 1)))\n",
    "model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, window_size, n_features))\n",
    "z1 = LSTM(n_neurons, return_sequences=True, stateful=stateful)(x)\n",
    "z2 = LSTM(n_neurons, return_sequences=False, stateful=stateful)(z1)\n",
    "z = Dense(n_classes, activation='softmax')(z2)\n",
    "# z = TimeDistributed(Dense(n_classes, activation='softmax'))(z2)\n",
    "\n",
    "model = Model(inputs=[x], outputs=[z])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, window_size, 1))\n",
    "z1 = PLSTM(n_neurons, return_sequences=True, implementation=2)(x)\n",
    "z2 = PLSTM(n_neurons, return_sequences=True, implementation=2)(z1)\n",
    "z = Dense(n_classes, activation='softmax')(z2)\n",
    "model = Model(inputs=[x], outputs=[z])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_filename = os.path.join(msig.out_dir, 'model_config.json')\n",
    "model_summary_filename = os.path.join(msig.out_dir, 'model_plot.png')\n",
    "with open(model_config_filename, 'w') as ofs:\n",
    "    json.dump(json.loads(model.to_json()), ofs, indent=4)\n",
    "plot_model(model, to_file=model_summary_filename, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid, *_ = msig.generate_samples(32)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "csvlogger = CSVLogger(msig.training_stats_filename, separator=',', append=True)\n",
    "checkpointer = ModelCheckpoint(msig.model_weights_filename, save_best_only=True, verbose=1)\n",
    "\n",
    "x_test, y_test = msig.generate_samples(1)\n",
    "test_dict = {\n",
    "    'sequence_type': msig.sequence_type,\n",
    "    'window_type': msig.window_type,\n",
    "    'window_size': msig.window_size,\n",
    "    'class_colors': np.hstack([wave.color for wave in msig.waves]),\n",
    "    'timestamps': msig.timestamps,\n",
    "    'X': x_test, \n",
    "    'y': y_test, \n",
    "    'y_hat': [],\n",
    "    'epoch': [], \n",
    "    'score': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_samples_train = 1024\n",
    "n_samples_valid = 256\n",
    "epochs = 100\n",
    "dump_every = 1\n",
    "status_update_every = 50\n",
    "# train_steps = msig.n_samples * n_samples_train // batch_size\n",
    "# test_steps = msig.n_samples * n_samples_test // batch_size\n",
    "\n",
    "x_valid, y_valid, *_ = msig.generate_samples(n_samples_valid)\n",
    "\n",
    "for i in range(epochs):\n",
    "    x_train, y_train, *_ = msig.generate_samples(n_samples_train)\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=1, \n",
    "        validation_data=(x_valid, y_valid),\n",
    "        batch_size=32,\n",
    "        verbose=1, \n",
    "        callbacks=[\n",
    "            csvlogger,\n",
    "            checkpointer\n",
    "        ],\n",
    "    )\n",
    "    if stateful:\n",
    "        model.reset_states()\n",
    "\n",
    "    if (i + 1) % dump_every == 0:     \n",
    "        test_dict['epoch'].append(i + 1)\n",
    "        score = model.evaluate(test_dict['X'], test_dict['y'], batch_size=batch_size)\n",
    "        if stateful:\n",
    "            model.reset_states()\n",
    "        test_dict['score'].append(score)\n",
    "\n",
    "        y_hat = model.predict(test_dict['X'], batch_size=batch_size)\n",
    "        if stateful:\n",
    "            model.reset_states()\n",
    "        test_dict['y_hat'].append(y_hat)\n",
    "\n",
    "    if (i + 1) % status_update_every == 0:\n",
    "        print('#' * 50)\n",
    "        print(f'Epoch: {(i + 1)}/{epochs}')\n",
    "        print('#' * 50)\n",
    "        model.save(msig.model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new test signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_stats = pd.read_csv(msig.training_stats_filename)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "# span = 111//30 = 3\n",
    "span = epochs // 125\n",
    "\n",
    "loss_dict = {\n",
    "    'loss': df_stats.loss,\n",
    "    'val_loss': df_stats.val_loss,\n",
    "    'loss (hw)': reversed_recombined_holt_winters(np.array(df_stats.loss), span=span),\n",
    "    'val_loss (hw)': reversed_recombined_holt_winters(np.array(df_stats.val_loss), span=span)\n",
    "\n",
    "}\n",
    "alphas = {\n",
    "    'loss': 0.3,\n",
    "    'val_loss': 0.3,\n",
    "    'loss (hw)': 1,\n",
    "    'val_loss (hw)': 1\n",
    "}\n",
    "\n",
    "legend_labels = []\n",
    "for key, value in loss_dict.items():\n",
    "    ax1.plot(value, alpha=alphas[key])\n",
    "    legend_labels.append(key)\n",
    "\n",
    "ax1.set_title(r'timestamps = {}, window_size = {}'.format(msig.n_timestamps, msig.window_size))\n",
    "ax1.set_xlabel(r'epoch')\n",
    "ax1.set_xlim((0, len(df_stats.acc)))\n",
    "ax1.set_ylabel(r'loss')\n",
    "ax1.set_ylim((0, None))\n",
    "ax1.grid(True)\n",
    "ax1.legend(legend_labels)\n",
    "\n",
    "acc_dict = {\n",
    "    'acc': df_stats.acc,\n",
    "    'val_acc': df_stats.val_acc,\n",
    "    'acc (hw)': reversed_recombined_holt_winters(np.array(df_stats.acc), span=span),\n",
    "    'val_acc (hw)': reversed_recombined_holt_winters(np.array(df_stats.val_acc), span=span)\n",
    "\n",
    "}\n",
    "alphas = {\n",
    "    'acc': 0.3,\n",
    "    'val_acc': 0.3,\n",
    "    'acc (hw)': 1,\n",
    "    'val_acc (hw)': 1\n",
    "}\n",
    "\n",
    "legend_labels = []\n",
    "for key, value in acc_dict.items():\n",
    "    ax2.plot(value, alpha=alphas[key])\n",
    "    legend_labels.append(key)\n",
    "\n",
    "ax2.set_title(r'neurons = {}, batch_size = {}'.format(n_neurons, batch_size))\n",
    "ax2.set_xlabel(r'epoch')\n",
    "ax2.set_xlim((0, len(df_stats.acc)))\n",
    "ax2.set_ylabel(r'accuracy')\n",
    "ax2.set_ylim((None, 1))\n",
    "ax2.grid(True)\n",
    "ax2.legend(legend_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(msig.out_dir, 'loss_accuracy.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test, y_test = msig.generate()\n",
    "# epoch = 0\n",
    "# score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "# if stateful:\n",
    "#     model.reset_states()\n",
    "# y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "# if stateful:\n",
    "#     model.reset_states()\n",
    "ii = 100\n",
    "x_test = test_dict['X']\n",
    "y_test = test_dict['y']\n",
    "score = test_dict['score'][ii]\n",
    "epoch = test_dict['epoch'][ii]\n",
    "y_hat = test_dict['y_hat'][ii]\n",
    "x_test_clipped = x_test[:, test_dict['window_size'] - 1:, 0]\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "y_pred = np.argmax(y_hat, axis=-1)\n",
    "\n",
    "print('x_test  {}'.format(x_test.shape))\n",
    "print('y_test  {}'.format(y_test.shape))\n",
    "print('y_true  {}'.format(y_true.shape))\n",
    "print(score)\n",
    "print('y_hat   {}'.format(y_hat.shape))\n",
    "print('y_pred  {}'.format(y_pred.shape))\n",
    "\n",
    "if msig.window_type == 'boxcar' and msig.network_type == 'RNN':\n",
    "    x_test_x_scatter = msig.timestamps\n",
    "    x_test_y_scatter = msig.mixed_signal\n",
    "    x_windows_start = np.reshape(msig.timestamps, y_pred.shape)[:, 0]\n",
    "    y_pred_colors = np.hstack([msig.waves[i].color for i in y_pred])\n",
    "elif msig.window_type == 'boxcar' and msig.network_type == 'MLP' and msig.sequence_type == 'many2many':\n",
    "    x_test_x_scatter = msig.timestamps\n",
    "    x_test_y_scatter = msig.mixed_signal\n",
    "    x_windows_start = np.reshape(msig.timestamps, y_pred.shape)[:, 0]\n",
    "    y_pred_colors = np.hstack([msig.waves[i].color for i in y_pred])\n",
    "elif msig.window_type == 'sliding':\n",
    "    x_test_x_scatter = msig.timestamps[msig.window_size-1:]\n",
    "    x_test_y_scatter = msig.mixed_signal[msig.window_size-1:]\n",
    "    x_windows_start = None\n",
    "    if msig.sequence_type == 'many2many':\n",
    "        y_true_colors = [msig.waves[i[-1]].color for i in y_true[0]]\n",
    "        y_pred_colors = [msig.waves[i[-1]].color for i in y_pred[0]]\n",
    "    else:\n",
    "        y_true_colors = np.hstack([msig.waves[i].color for i in y_true[0]])\n",
    "        y_pred_colors = np.hstack([msig.waves[i].color for i in y_pred[0]])\n",
    "\n",
    "# print('y_colors{}'.format(y_pred_colors.shape))\n",
    "# print(msig.timestamps.shape)\n",
    "# print(x_test_x_scatter.shape)\n",
    "# print(x_test_y_scatter.shape)\n",
    "# print(x_windows_start)\n",
    "\n",
    "# I derived y_score based on my intuition (i.e. out of thin air).  Would be nice to find some theoretical justification for why this is I like it so much.\n",
    "if msig.sequence_type == 'many2many':\n",
    "    y_true_value = [y_hat[i, j, y_true[i, j]] for i in range(y_true.shape[0]) for j in range(y_true.shape[1])]\n",
    "    y_pred_value = [y_hat[i, j, y_pred[i, j]] for i in range(y_pred.shape[0]) for j in range(y_pred.shape[1])]\n",
    "    y_true_value = np.reshape(y_true_value, y_true.shape)\n",
    "    y_pred_value = np.reshape(y_pred_value, y_pred.shape)\n",
    "    y_penalty = y_true_value - y_pred_value\n",
    "    y_score = y_true_value + y_penalty\n",
    "else:\n",
    "    y_true_value = y_hat[(np.arange(y_true.shape[0]), y_true[0])]\n",
    "    y_pred_value = y_hat[(np.arange(y_pred.shape[0]), y_pred[0])]\n",
    "    y_penalty = y_true_value - y_pred_value\n",
    "    y_score = y_true_value + y_penalty\n",
    "    # Hack: Make y_score the same shape as many2many y_score\n",
    "#     y_score = y_score[:, None] * np.ones((msig.window_size,))[None, :]\n",
    "    \n",
    "print(y_true_value.shape)\n",
    "print(y_pred_value.shape)\n",
    "print(y_penalty.shape)\n",
    "print(y_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msig.mixed_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true_colors[:4])\n",
    "print(test_dict['class_colors'][y_true][:4])\n",
    "test_dict['sequence_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat[:4])\n",
    "print(y_true[:4])\n",
    "print(y_true_value[:4])\n",
    "print(y_hat[(np.arange(y_true.shape[0]), y_true)][:4])\n",
    "print(y_pred_value[:4])\n",
    "print(y_hat[(np.arange(y_pred.shape[0]), y_pred)][:4])\n",
    "print(y_penalty)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 10\n",
    "# s0 = slice(0, j)\n",
    "# s1 = slice(-j, -1)\n",
    "# s0 = s1\n",
    "# print(y_hat[s0, s1])\n",
    "# print(y_true[s0, s1])\n",
    "# print(y_true_value[s0, s1])\n",
    "# print(y_pred[s0, s1])\n",
    "# print(y_pred_value[s0, s1])\n",
    "# print(y_penalty[s0, s1])\n",
    "# print(y_score[s0, s1])\n",
    "# print(np.min(y_score), np.max(y_score))\n",
    "\n",
    "if msig.sequence_type == 'many2many':\n",
    "    y_score_mean = y_score.sum(axis=1) / y_score.shape[1]\n",
    "    y_score_unshifted = np.zeros((msig.n_timestamps, msig.window_size))\n",
    "    for i in range(msig.window_size):\n",
    "        y_score_unshifted[i:i + msig.n_samples, i] = y_score[:, i]\n",
    "    y_score_unshifted_clipped = y_score_unshifted[msig.window_size-1:]\n",
    "    y_score_unshifted_clipped_mean = y_score_unshifted_clipped.sum(axis=1) / y_score.shape[1]\n",
    "else:\n",
    "    \n",
    "    y_score_mean = y_score.sum(axis=1) / y_score.shape[1]\n",
    "    y_score_unshifted = np.zeros((msig.n_timestamps, msig.window_size))\n",
    "    for i in range(msig.window_size):\n",
    "        y_score_unshifted[i:i + msig.n_samples, i] = y_score[:, i]\n",
    "    y_score_unshifted_clipped = y_score_unshifted[msig.window_size-1:]\n",
    "    y_score_unshifted_clipped_mean = y_score_unshifted_clipped.sum(axis=1) / y_score.shape[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = 0\n",
    "xmax = y_score.shape[0]\n",
    "xindex = range(xmin, xmax)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(10, 16))\n",
    "# ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "# ax.set_axis_off()\n",
    "# fig.add_axes(ax)\n",
    "\n",
    "ax[0].scatter(\n",
    "    xindex, \n",
    "    x_test_clipped, \n",
    "    marker='.', \n",
    "    c=y_true_colors)\n",
    "ax[0].set_title('epoch = {}'.format(epoch))\n",
    "ax[0].set_xlim((xmin, xmax))\n",
    "ax[0].set_xticks([])\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].imshow(\n",
    "    y_score.T, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.get_cmap('Spectral'), \n",
    "    origin='upper');\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].set_xlim((xmin, xmax))\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_ylim((y_score.shape[1], 0))\n",
    "ax[1].set_yticks([y_score.shape[1]])\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "ax1Top = divider.append_axes(\"top\", 0.5, sharex=ax[1])\n",
    "ax1Top.xaxis.set_tick_params(labelbottom=False)\n",
    "ax1Top.plot(y_score_mean)\n",
    "ax1Top.set_title('sequence model type = {}'.format(msig.sequence_type))\n",
    "ax1Top.set_xlim((xmin, xmax))\n",
    "ax1Top.set_ylim((-1, 1))\n",
    "ax1Top.set_yticks((-1, 0, 1))\n",
    "ax1Top.grid(True)\n",
    "\n",
    "ax[2].imshow(\n",
    "    y_score_unshifted_clipped.T, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.get_cmap('Spectral'), \n",
    "    origin='upper');\n",
    "ax[2].spines['top'].set_visible(False)\n",
    "ax[2].set_xlim((xmin, xmax))\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_ylim((y_score_unshifted_clipped.shape[1], 0))\n",
    "ax[2].set_yticks([y_score_unshifted_clipped.shape[1]])\n",
    "\n",
    "divider = make_axes_locatable(ax[2])\n",
    "ax2Top = divider.append_axes(\"top\", 0.5, sharex=ax[2])\n",
    "ax2Top.xaxis.set_tick_params(labelbottom=False)\n",
    "ax2Top.plot(y_score_unshifted_clipped_mean)\n",
    "ax2Top.set_title('{} window size = {}'.format(window_type, msig.window_size))\n",
    "ax2Top.set_xlim((xmin, xmax))\n",
    "ax2Top.set_ylim((-1, 1))\n",
    "ax2Top.set_yticks((-1, 0, 1))\n",
    "ax2Top.grid(True)\n",
    "\n",
    "ax[3].scatter(\n",
    "    xindex, \n",
    "    x_test_clipped,\n",
    "    marker='.', \n",
    "    c=y_pred_colors)\n",
    "ax[3].set_title('loss = {:<6.4f}, accuracy = {:<.2%}'.format(*score))\n",
    "ax[3].set_xlim((xmin, xmax))\n",
    "ax[3].grid(True)\n",
    "\n",
    "# plt.draw()\n",
    "plt.savefig(os.path.join(msig.out_dir, 'prediction_analysis.png'), bbox_inches='tight', pad_inches=0.08)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if msig.sequence_type == 'many2many':\n",
    "    plot_confusion_matrix(y_true[:, -1], y_pred[:, -1], figsize=(8, 6), filename=os.path.join(msig.out_dir, 'confusion_matrix.png'))\n",
    "else:\n",
    "    plot_confusion_matrix(y_true[0], y_pred[0], figsize=(8, 6), filename=os.path.join(msig.out_dir, 'confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_utils);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mixsig.plot_utils as plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_utils.plot_prediction_tests(test_dict, os.path.join(msig.out_dir, 'training_snapshots'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now browse to the training_snapshots folder and run,\n",
    "```bash\n",
    "ffmpeg -framerate 30 -i %05d.png -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p ../prediction_analysis.mp4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixsig.utils import factors\n",
    "# CODE\n",
    "# fact_a = factors(self.batch_size)\n",
    "# fact_b = factors(self.window_size)\n",
    "# gcm = max(fact_a.intersection(fact_b))\n",
    "# chop_index = len(timestamps) % (self.window_size * self.batch_size // gcm)\n",
    "\n",
    "# TODO: Move this to unit tests\n",
    "ws, bs = 512, 392\n",
    "nts = 200771\n",
    "print(f'nts   = {nts}\\nws*bs = {ws * bs}')\n",
    "print(factors(nts))\n",
    "\n",
    "fact_a = factors(bs)\n",
    "print(fact_a)\n",
    "fact_b = factors(ws)\n",
    "print(fact_b)\n",
    "gcm = max(fact_a.intersection(fact_b))\n",
    "print(gcm)\n",
    "\n",
    "print('#'*20)\n",
    "print(ws * bs // gcm)\n",
    "print(nts % (ws * bs // gcm))\n",
    "nts2 = nts - (nts % (ws * bs // gcm))\n",
    "print(nts2, nts2 // bs, nts2 // ws)\n",
    "\n",
    "print('#'*20)\n",
    "print(ws * bs)\n",
    "print(nts % (ws * bs))\n",
    "nts2 = nts - (nts % (ws * bs))\n",
    "print(nts2, nts2 // bs, nts2 // ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sequences = []\n",
    "for i in range(20):\n",
    "    seq = random.sample(range(50), random.randint(10, 20))\n",
    "    print(len(seq), seq)\n",
    "    raw_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequences = pad_sequences(\n",
    "    raw_sequences, \n",
    "    maxlen=15, \n",
    "    dtype='int32', \n",
    "    padding='pre', \n",
    "    truncating='post', \n",
    "    value=0.0)\n",
    "\n",
    "print(new_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.plot(y_score.sum(axis=0) / y_score.shape[0])\n",
    "plt.xlim((0, y_score.shape[1]))\n",
    "plt.xlabel('timestep')\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('classifier score')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'mean_accuracy_vs_timestep.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## current validation signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape)\n",
    "print(hidden_layers['1'].shape)\n",
    "print(output_layers.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape)\n",
    "print(hidden_layers['1']['output'].shape)\n",
    "print(hidden_layers['1']['state'].shape)\n",
    "print(z1_layers.shape)\n",
    "print(output_layers.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.reshape(z2_layers[..., 5], (1000, 1000))\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "im = ax.imshow(arr, interpolation=\"none\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(msig.out_dir, 'gen_loss_acc.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = '1'\n",
    "o_or_s = 'output'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\n",
    "print(val_arrays.shape)\n",
    "glance_at_tensor(val_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/home/maddoxw/PycharmProjects/MixSig/out/2018-04-09_04-53-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_arrays = np.load(os.path.join(vsig.out_dir, 'valid_output_layer.npy'))\n",
    "print(val_arrays.shape)\n",
    "glance_at_tensor(val_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_hat = model.predict(x_val, batch_size=batch_size)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(states['y_hat'], axis=1)\n",
    "# y_pred_colors = np.hstack([vsig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "layer = '1'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, 'valid_hidden_layer_' + layer + '_output.npy'))\n",
    "n_generations, _, n_neurons = val_arrays.shape\n",
    "ncols = 1\n",
    "nrows = n_neurons // ncols\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 3))\n",
    "\n",
    "for g in range(n_generations):\n",
    "    for i in range(n_neurons):\n",
    "        ax = axes#[i // ncols, i % ncols]\n",
    "        ax.cla()\n",
    "        y_pred_colors = val_arrays[g, :, i]\n",
    "        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n",
    "        ax.scatter(\n",
    "            vsig.timestamps[vsig.window_size-1:], \n",
    "#             vsig.timestamps, \n",
    "#             x_val[:, -1, 0], \n",
    "#             x_val[0, :, 0], \n",
    "            vsig.mixed_signal[vsig.window_size-1:], \n",
    "            marker='o', \n",
    "            c=y_pred_colors, \n",
    "            cmap=plt.get_cmap('coolwarm'), \n",
    "            vmin=-1, \n",
    "            vmax=1\n",
    "        )\n",
    "        ax.set_title('neuron = {}'.format(i + 1))\n",
    "        ax.set_xlim((vsig.t_min, vsig.t_max))\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, 'output', g + 1))\n",
    "#     plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, 'gen', str(g + 1)]) + '.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(states['y_hat'], axis=1)\n",
    "# y_pred_colors = np.hstack([vsig.signal_colors[i] for i in y_pred])\n",
    "\n",
    "layer = '2'\n",
    "o_or_s = 'output'\n",
    "val_arrays = np.load(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s])) + '.npy')\n",
    "n_generations, _, n_neurons = val_arrays.shape\n",
    "ncols = 2\n",
    "nrows = n_neurons // ncols\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 20))\n",
    "\n",
    "for g in range(n_generations):\n",
    "    for i in range(n_neurons):\n",
    "        ax = axes[i // ncols, i % ncols]\n",
    "        ax.cla()\n",
    "        y_pred_colors = val_arrays[g, :, i]\n",
    "        ax.plot(vsig.timestamps, vsig.mixed_signal, color='grey', alpha=0.3)\n",
    "        ax.scatter(\n",
    "#             vsig.timestamps[vsig.window_size-1:], \n",
    "            vsig.timestamps, \n",
    "#             x_val[:, -1, 0], \n",
    "            x_val[0, :, 0], \n",
    "            vsig.timestamps[vsig.window_size-1:], \n",
    "            marker='o', \n",
    "            c=y_pred_colors, \n",
    "            cmap=plt.get_cmap('coolwarm'), \n",
    "            vmin=-1, \n",
    "            vmax=1\n",
    "        )\n",
    "        ax.set_title('neuron = {}'.format(i + 1))\n",
    "        ax.set_xlim((vsig.t_min, vsig.t_max))\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('hidden layer = {}, ({}), generation = {}'.format(layer, o_or_s, g + 1))\n",
    "    plt.savefig(os.path.join(vsig.out_dir, '_'.join(['valid_hidden_layer', layer, o_or_s, 'gen', str(g + 1)]) + '.png'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "y_hat, *args = model2.predict(x_test, batch_size=batch_size)\n",
    "model2.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=-1)\n",
    "print('x_test', x_test.shape, '{:>9.4f} {:>9.4f}'.format(np.min(x_test), np.max(x_test)))\n",
    "print('y_test', y_test.shape)\n",
    "print('y_hat ', y_hat.shape, '{:>9.4f} {:>9.4f}'.format(np.min(y_hat), np.max(y_hat)))\n",
    "print('y_pred', y_pred.shape, '{} {}'.format(np.min(y_pred), np.max(y_pred)))\n",
    "for i, arg in enumerate(args):\n",
    "    print(i, arg.shape, '{:>9.4f} {:>9.4f}'.format(np.min(arg), np.max(arg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_colors = np.hstack([msig.waves[i].color for i in y_pred])\n",
    "print(y_pred_colors[:3])\n",
    "print(y_pred.shape, y_pred_colors.shape)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "# ax.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred_colors)\n",
    "# ax.scatter(msig.timestamps, x_test[0, :, 0], marker='.', c=y_pred_colors)\n",
    "ax.scatter(msig.timestamps[msig.window_size-1:], msig.mixed_signal[msig.window_size-1:], marker='.', c=y_pred_colors)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "# y_pred_colors = [msig.waves[i].color for i in msig.labels[msig.window_size-1:]]\n",
    "y_pred_colors = np.hstack([msig.waves[i].color for i in y_pred])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 3))\n",
    "ax.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred_colors)\n",
    "ax.set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax.set_xlabel('time')\n",
    "ax.set_xlim((msig.t_min, msig.t_max))\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(msig.out_dir, 'eval_pred.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig.generate()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "model.reset_states()\n",
    "print(score)\n",
    "\n",
    "y_hat = model.predict(x_test, batch_size=batch_size)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "# y_error = 1.0 - np.max(y_hat, axis=1)\n",
    "model.reset_states()\n",
    "# print(y_hat.shape)\n",
    "print(y_pred.shape)\n",
    "# print(y_error.shape)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 6))\n",
    "\n",
    "ax[0].plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "ax[0].scatter(msig.timestamps, msig.mixed_signal, marker='.')\n",
    "ax[0].set_title('loss = {:<6.4f}, accuracy = {:<6.4f}'.format(*score))\n",
    "ax[0].set_xlim((msig.t_min, msig.t_max))\n",
    "\n",
    "ax[1].plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "ax[1].scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "ax[1].set_xlim((msig.t_min, msig.t_max))\n",
    "ax[1].set_xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer weights to new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n_batch = 1\n",
    "print(X.shape)\n",
    "print(n_batch)\n",
    "# re-define model\n",
    "new_model = Sequential()\n",
    "new_model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
    "new_model.add(LSTM(n_neurons))\n",
    "new_model.add(Dense(msig.n_classes, activation='softmax'))\n",
    "# copy weights\n",
    "old_weights = model.get_weights()\n",
    "new_model.set_weights(old_weights)\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "x_test, y_test = msig.generate()\n",
    "score = new_model.evaluate(x_test, y_test, batch_size=n_batch)\n",
    "print(score)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps, msig.mixed_signal, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps, msig.mixed_signal, marker='.', c=msig.one_hots)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "for i in range(len(x_test)):\n",
    "    print('Expected', y_test[i], 'Predicted', y_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x_test, y_test = msig()\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "y_hat = new_model.predict(x_test, batch_size=msig.n_samples)\n",
    "print(y_hat.shape)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "print(y_pred.shape)\n",
    "y_error = np.max(y_hat, axis=1)\n",
    "print(y_error.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[msig.window_size-1:], x_test[:, -1, 0], marker='.', c=y_error)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(msig.timestamps[-msig.n_samples:], y_error, color='grey', alpha=0.3)\n",
    "plt.scatter(msig.timestamps[-msig.n_samples:], y_error, marker='.', c=y_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeDistributed testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-One LSTM for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(length, 1, 1)\n",
    "y = seq.reshape(length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = length\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "# print(X)\n",
    "# print(result)\n",
    "for value in result:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-One LSTM for Sequence Prediction (without TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "# define LSTM configuration\n",
    "n_neurons = length\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1)))\n",
    "model.add(Dense(length))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "print(X)\n",
    "print(result)\n",
    "for value in result[0,:]:\n",
    "    print('%.1f' % value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many LSTM for Sequence Prediction (with TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 19\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = 5\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many LSTM for Sequence Prediction (without TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sequence\n",
    "length = 19\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length, 1)\n",
    "# define LSTM configuration\n",
    "n_neurons = 5\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(length, 1), return_sequences=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "for x, value in zip(X[0, :, 0], result[0, :, 0]):\n",
    "    print('{:>.2f} {:>.3f}'.format(x, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
    "print(X.shape, result.shape)\n",
    "for x, value in zip(X[0, :, 0], result[0, :, 0]):\n",
    "    print('{:>.2f} {:>.3f}'.format(x, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "    return pd.datetime.strptime('190'+x, '%Y-%m')\n",
    "series = pd.read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "print(series.head())\n",
    "# transform to be stationary\n",
    "differenced = difference(series, 1)\n",
    "print(differenced.head())\n",
    "# invert transform\n",
    "inverted = list()\n",
    "for i in range(len(differenced)):\n",
    "    value = inverse_difference(series, differenced[i], len(series)-i)\n",
    "    inverted.append(value)\n",
    "inverted = pd.Series(inverted)\n",
    "print(inverted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # this example is too small to use anything larger than 1.\n",
    "window_size = 7  # This is the size after unrolling.\n",
    "n_features = 1  # Assume each red square represents a single number.\n",
    "n_layers = 3  # These are the middle 3 horizontal layers.\n",
    "n_neurons = 2  # One neuron for the green block(s) and one for the yellow.\n",
    "n_outputs = 7  # because it's many to many.\n",
    "\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "X = seq.reshape(1, length, 1)\n",
    "y = seq.reshape(1, length)\n",
    "\n",
    "x = Input(batch_shape=(batch_size, window_size, n_features))  # bottom row of red blocks.\n",
    "h = LSTM(n_neurons, return_sequences=True)(x)  # hidden layer 1\n",
    "h = LSTM(n_neurons, return_sequences=True)(h)  # hidden layer 2\n",
    "h = LSTM(n_neurons, return_sequences=True)(h)  # hidden layer 3\n",
    "z = TimeDistributed(Dense(n_outputs, activation='softmax'))(h)  # top row of blue blocks\n",
    "model = Model(inputs=[x],outputs=[z])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "import numpy\n",
    "from numpy import concatenate\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    return df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "    diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "    new_row = [x for x in X] + [yhat]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    "\n",
    "# run a repeated experiment\n",
    "def experiment(repeats, series):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series.values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, 1)\n",
    "    supervised_values = supervised.values[1:,:]\n",
    "    # split data into train and test-sets\n",
    "    train, test = supervised_values[0:-12, :], supervised_values[-12:, :]\n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(repeats):\n",
    "        # fit the base model\n",
    "        lstm_model = fit_lstm(train_scaled, 1, 1000, 1)\n",
    "        # forecast test dataset\n",
    "        predictions = list()\n",
    "        for i in range(len(test_scaled)):\n",
    "            # predict\n",
    "            X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "            yhat = forecast_lstm(lstm_model, 1, X)\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores\n",
    "\n",
    "# execute the experiment\n",
    "def run():\n",
    "    # load dataset\n",
    "    series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "    # experiment\n",
    "    repeats = 10\n",
    "    results = DataFrame()\n",
    "    # run experiment\n",
    "    results['results'] = experiment(repeats, series)\n",
    "    # summarize results\n",
    "    print(results.describe())\n",
    "    # save results\n",
    "    results.to_csv('experiment_stateful.csv', index=False)\n",
    "\n",
    " # entry point\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=True, shuffle=False\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=False, shuffle=False\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data. stateful=False, shuffle=True\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=False))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load results into a dataframe\n",
    "filenames = ['experiment_stateful.csv', 'experiment_stateful2.csv']\n",
    "results = DataFrame()\n",
    "for name in filenames:\n",
    "    results[name[11:-4]] = read_csv(name, header=0)\n",
    "# describe all results\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load results into a dataframe\n",
    "filenames = ['experiment_stateful.csv', 'experiment_stateless.csv', 'experiment_stateless_shuffle.csv']\n",
    "results = DataFrame()\n",
    "for name in filenames:\n",
    "    results[name[11:-4]] = read_csv(name, header=0)\n",
    "# describe all results\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "results.boxplot()\n",
    "pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
